### Model configuration ###

experiment_name: tts_cfm

dirs:
  logging: tts_experiments

seed: 1234

batch:
  type: TTSBatchProcessor

data_loaders:
  batch_size: { default: 24, debug: 4 }
  min_batch_size: 4
  min_prefetch_factor: { default: 50, debug: 1 }
  max_prefetch_factor: { default: 150, debug: 1 }

trainer:
  accelerator: { default: gpu, debug: cpu }
  devices: { default: [auto], debug: 1 }
  max_epochs: 150
  gradient_clip_val: 5.0
  accumulate_grad_batches: 1
  # resume_from_checkpoint: /path/to/checkpoint

checkpoint:
  monitor: Epoch
  mode: max
  save_top_k: 30
  every_n_epochs: 5
  save_last: False

callbacks:
  TTSTrainingVisualizer: {}

optimizer:
  method:
    type: Adam
    weight_decay: 1.e-6
  lr_scheduler:
    type: ConstLR
    lr_max: 1.e-4

loss:
  type: TTSLoss
  Spectral:
    loss_fn: l1
    scale: 0.8
  DiffSpectral:
    loss_fn: l1
    scale: 0.2
  VAELoss:
    scale: 0.00002
    every_iter: 1
    begin_iter: 1000
    end_anneal_iter: 10000
  InverseSpeakerLoss:
    type: InverseSpeakerLoss

model:
  type: ParallelTTSModel
  params:
    token_emb_dim: 256

    use_mean_dnn_speaker_emb: true
    speaker_biometric_model: wespeaker
    speaker_emb_dim: 64

    use_average_emb: true
    averages:
      rate:
        interval: [0, 64]
      energy:
        interval: [0, 150]

    mode_cat:
      1: [average_emb, speech_quality_emb]

    encoder_type: ForwardEncoder
    encoder_inner_dim: 1024
    encoder_params:
      tag: encoder
      base_encoder_type: RNNEncoder
      base_encoder_params:
        cat_ling_feat: true
        cat_lm_feat: false
        condition: [speaker_emb]
        condition_dim: 64
      base_adaptor_encoder_type: RNNEncoder
      base_adaptor_encoder_params:
        cat_ling_feat: true
        cat_lm_feat: false
        condition: [speaker_emb]
        condition_dim: 64

    va_type: HierarchicalVarianceAdaptor

    decoder_type: WrapperDecoder
    decoder_inner_dim: 1024
    decoder_params:
      tag: decoder
      base_decoder_type: RNNEncoder
      base_decoder_params:
        condition: [speaker_emb, style_emb]
        condition_dim: 192

    postnet_type: CFMPostnet
    postnet_inner_dim: 384
    postnet_params:
      tag: postnet
      condition: [speaker_emb]
      condition_dim: 64

      attention_head_dim: 128
      n_blocks: 1
      n_mid_blocks: 2
      n_heads: 4
      norm_type: ada_norm_zero

    addm_apply_inverse_speaker_classifier:
      StyleEncoder_0: 128

    va_variances:
      0: [spectrogram_style_encoder]
      1: [aggregate_energy, aggregate_pitch]
      2: [aggregate_curv_energy, aggregate_curv_pitch]
      3: [durations]
      4: [energy, pitch]
    va_variance_params:
      biometric_style_encoder:
        tag: style_emb
        as_encoder: true
        predictor_type: StyleEncoder
        predictor_params:
          vp_output_dim: 128
          vp_params:
            base_encoder_type: SimpleStyle
            source: ecapa_emb
            source_dim: 192
            use_gmvae: true
            gmvae_n_components: 16
      spectrogram_style_encoder:
        tag: style_emb
        as_encoder: true
        predictor_type: StyleEncoder
        predictor_params:
          vp_output_dim: 128
          vp_params:
            base_encoder_type: StyleSpeech  # StyleSpeech, StyleTTS2
            source: spectrogram  # spectrogram, ssl_feat
            source_dim: 80  # 80, 768
      aggregate_energy:
        predictor_type: TokenLevelPredictorWithDiscriminator
        as_embedding: true
        interval: [0, 1.5]
        n_bins: 256
        emb_dim: 64
        input_content: [1]
        cat_to_content: [1]
      aggregate_pitch:
        predictor_type: TokenLevelPredictorWithDiscriminator
        log_scale: true
        as_embedding: true
        interval: [0, 1.5]
        n_bins: 256
        emb_dim: 64
        input_content: [1]
        cat_to_content: [1]
      aggregate_curv_energy:
        predictor_type: TokenLevelPredictor
        dim: 2
        as_embedding: true
        interval: [-1.58, 1.58]
        n_bins: 256
        emb_dim: 64
        input_content: [1]
        cat_to_content: [1]
      aggregate_curv_pitch:
        predictor_type: TokenLevelPredictor
        dim: 2
        as_embedding: true
        interval: [-1.58, 1.58]
        n_bins: 256
        emb_dim: 64
        input_content: [1]
        cat_to_content: [1]
      durations:
        input_content: [0]
        predictor_type: TokenLevelDPWithDiscriminator
        predictor_params:
          vp_params:
            add_noise: true
        denormalize: true
      energy:
        predictor_type: FrameLevelPredictorWithDiscriminator
        denormalize: false
        as_embedding: true
        interval: [0, 1.5]
        n_bins: 256
        emb_dim: 128
        input_content: [1]
        cat_to_content: [0]
      pitch:
        predictor_type: FrameLevelPredictorWithDiscriminator
        predictor_params:
          vp_params:
            use_ssl_adjustment: true
        denormalize: false
        log_scale: true
        as_embedding: true
        interval: [0, 1.5]
        n_bins: 256
        emb_dim: 128
        input_content: [1]
        cat_to_content: [0]
