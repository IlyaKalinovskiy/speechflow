### Model configuration ###

experiment_name: tts_froward

dirs:
  logging: tts_experiments

seed: 1234

batch:
  type: TTSBatchProcessor

data_loaders:
  batch_size: { default: 24, debug: 4 }
  min_batch_size: 4
  min_prefetch_factor: { default: 50, debug: 1 }
  max_prefetch_factor: { default: 150, debug: 1 }

trainer:
  accelerator: gpu
  devices: { default: [auto], debug: 0 }
  max_epochs: 150
  gradient_clip_val: 5.0
  accumulate_grad_batches: 1

checkpoint:
  monitor: Epoch
  mode: max
  save_top_k: 30
  every_n_epochs: 10
  save_last: False

callbacks:
  TTSTrainingVisualizer: {}

optimizer:
  method:
    type: Adam
    weight_decay: 1.e-6
  lr_scheduler:
    type: WarmupInvRsqrtLR
    lr_max: 0.001

loss:
  type: TTSLoss
  Spectral:
    loss_fn: l1
    scale: 0.8
  DiffSpectral:
    loss_fn: l1
    scale: 0.2
  TokenDurations:
    loss_fn: l1
    every_iter: 2
  AggregateEnergy:
    loss_fn: l1
  AggregatePitch:
    loss_fn: l1
  AggregateCurvEnergy:
    loss_fn: l1
  AggregateCurvPitch:
    loss_fn: l1
  Energy:
    loss_fn: l1
  Pitch:
    loss_fn: l1
  Gate:
    loss_fn: BCEl
  VAELoss:
    scale: 0.00002
    every_iter: 1
    begin_iter: 1000
    end_anneal_iter: 10000
  InverseSpeakerLoss:
    type: InverseSpeakerLoss

net:
  type: ParallelTTSModel
  params:
    token_emb_dim: 256

    use_learnable_speaker_emb: True
    speaker_emb_dim: 32

    use_average_emb: True
    averages:
      energy:
        interval: [0, 150]

    mode_cat:
      1: [speaker_emb, average_emb, speech_quality_emb]

    encoder_type: ForwardEncoder
    va_type: ForwardVarianceAdaptor
    decoder_type: ForwardDecoder
    decoder_inner_dim: 1024

    # addm_apply_inverse_speaker_classifier:
    #   style_emb: 64

    va_variances:
      # 0: [spectrogram_encoder]
      1: [aggregate_energy, aggregate_pitch]
      2: [aggregate_curv_energy, aggregate_curv_pitch]
      3: [durations]
      4: [energy, pitch]
    va_variance_params:
      speaker_embedding_encoder:
        dim: 192
        predictor_type: GMVariationalAutoencoder
        predictor_params:
          vp_latent_dim: 64
          vp_vae_encoder_condition: [target]
          vp_vae_encoder_type: SimpleStyle
          vp_gmvae_n_components: 16
      spectrogram_encoder:
        predictor_type: StyleEncoder
        predictor_params:
          vp_params:
            base_encoder_type: StyleTTS2  # StyleTTS2, StyleSpeech
            condition: [mel_spectrogram]  # style_condition, ssl_embeddings
            condition_dim: 80  # 80, 768
            style_embedding_size: 128
        cat_to_content: []
        tag: style_emb
      aggregate_energy:
        predictor_type: TokenLevelPredictor
        as_embedding: True
        interval: [0, 1.5]
        n_bins: 256
        emb_dim: 64
        cat_to_content: [1]
      aggregate_pitch:
        predictor_type: TokenLevelPredictor
        log_scale: True
        as_embedding: True
        interval: [0, 1.5]
        n_bins: 256
        emb_dim: 64
        cat_to_content: [1]
      aggregate_curv_energy:
        predictor_type: TokenLevelPredictor
        dim: 2
        as_embedding: True
        interval: [-1.58, 1.58]
        n_bins: 256
        emb_dim: 64
        cat_to_content: [1]
      aggregate_curv_pitch:
        predictor_type: TokenLevelPredictor
        dim: 2
        as_embedding: True
        interval: [-1.58, 1.58]
        n_bins: 256
        emb_dim: 64
        cat_to_content: [1]
      durations:
        predictor_type: TokenLevelDP
        denormalize: True
      energy:
        predictor_type: FrameLevelPredictor
        denormalize: True
        as_embedding: True
        interval: [0, 150]
        n_bins: 256
        emb_dim: 128
        cat_to_content: [0]
      pitch:
        predictor_type: FrameLevelPredictor
        denormalize: True
        log_scale: True
        as_embedding: True
        interval: [0, 880]
        n_bins: 256
        emb_dim: 128
        cat_to_content: [0]
