### Data configuration ###

dirs:
  data_root: &data_root ../../../examples/simple_datasets/speech/SEGS
  dump_folder: &dump_folder dump_24KHz_lm_ssl

file_search:
  ext: .TextGridStage3
  with_subfolders: true

data_server:
  n_processes: { default: 8, debug: 1 }
  n_gpus: { default: 0, debug: 0 }

dataset:
  subsets: [train, test]
  split_type: auto  # auto, manual
  split_ratio: { default: 0.999, debug: 0.5 }
  max_num_samples: { default: 0, debug: 40 }
  directory_filter:
    exclude:
      default: ["!"]

parser:
  type: TTSDSParser
  dump: !join [*data_root, *dump_folder]
  pipe: [audio_strip, split_by_phrases, check_phoneme_length, get_simple_intonation_type]
  pipe_cfg:
    audio_strip:
      pad: 0.25
      add_fade: true
    split_by_phrases:
      max_duration: 15  # 10, 12, 15
    check_phoneme_length:
      max_len: 0.4
    get_simple_intonation_type:
      punctuation_marks: [".", "?"]

preproc:
  pipe: [load_audio, load_text_from_sega,
         voice_bio_speechbrain, store_bio_emb, voice_bio_wespeaker, mean_bio_embedding,
         speech_quality, spectrogram, melscale, add_gate_value,
         pitch, enhancement_energy, enhancement_pitch,
         add_pauses_from_timestamps, add_service_tokens, text,
         int_durations, calc_invert_durations, phonemes_by_frames, float_durations,
         curvature_estimate_by_phoneme, average_by_time, norm_1, aggregate_by_phoneme, norm_2,
         lm, ssl_features]
  pipe_cfg:
    load_audio:
      type: SignalProcessor
      pipe: [load]
      pipe_cfg:
        load:
          sample_rate: 24000
    voice_bio_speechbrain:
      type: VoiceBiometricProcessor
      model_type: speechbrain
      max_audio_duration: 5
      random_crop: true
    store_bio_emb:
      type: store_field
      key: speaker_emb
      as_key: ecapa_emb
    voice_bio_wespeaker:
      type: VoiceBiometricProcessor
      model_type: wespeaker
      max_audio_duration: 5
      random_crop: true
    speech_quality:
      type: SpeechQualityAssessment
      max_audio_duration: 5
      random_crop: true
    spectrogram:
      type: SpectralProcessor
      pipe: [magnitude, energy]
      pipe_cfg:
        magnitude:
          n_fft: 1024
          hop_len: 320
          win_len: 1024
    melscale:
      type: MelProcessor
      pipe: [linear_to_mel, amp_to_db, normalize]
      pipe_cfg:
        linear_to_mel:
          n_mels: 80
          f_min: 0
          f_max: 8000
    pitch:
      type: PitchProcessor
      method: pyworld
    enhancement_energy:
      type: signal_enhancement
      attributes: energy
      smooth: true
    enhancement_pitch:
      type: signal_enhancement
      attributes: pitch
      smooth: true
    add_pauses_from_timestamps:
      step: 0.05
      calc_noise_level: true
    text:
      type: TextProcessor
      lang: { default: MULTILANG, ru: RU, en: EN, ml: MULTILANG }
    norm_1:
      type: normalize
      attributes: [energy, pitch]
      normalize_by: speaker
    aggregate_by_phoneme:
      attributes: [energy, pitch, mel]
      agg: mean
    curvature_estimate_by_phoneme:
      attributes: [energy, pitch]
    norm_2:
      type: normalize
      attributes: [durations]
      normalize_by: speaker
    average_by_time:
      attributes: [durations, energy, pitch, rate]
      use_quantile: true
    int_durations:
      type: calc_durations
      as_int: true
    calc_invert_durations:
      token_level: true
    float_durations:
      type: calc_durations
      as_int: False
    lm:
      type: LMProcessor
      lang: { default: MULTILANG, ru: RU, en: EN }
      model_dir:
        default: multilingual_text_parser/data/common/xlm-roberta-large
        ru: multilingual_text_parser/data/ru/homo_classifier
        en: multilingual_text_parser/data/en/roberta_large
        ml: multilingual_text_parser/data/common/xlm-roberta-large
      model_name: { default: model, ru: ruRoBerta }
      by_phonemes: False
    ssl_features:
      type: SSLProcessor
      ssl_type: { default: Wav2Vec, ml: WavLM }
      resize_from: mel

singleton_handlers:
  handlers: [SpeakerIDSetter, StatisticsRange, MeanBioEmbeddings]
  SpeakerIDSetter: {}
    # langs_filter: RU
    # min_duration: { default: 1.0, debug: ~ }
    # resume_from_checkpoint: /path/to/checkpoint
  StatisticsRange:
    statistics_file: !join [*data_root, *dump_folder, ranges.json]
  MeanBioEmbeddings:
    mean_embeddings_file: !join [*data_root, *dump_folder, mean_bio_embeddings.json]
  DatasetStatistics:
    dump: !join [*data_root, *dump_folder]

collate:
  type: TTSCollate
  # multiple:
  #  spec: 16

processor:
  type: DataProcessor
  output_collated_only: true
  dump:
    default:
      data_root: *data_root
      folder_path: !join [*data_root, *dump_folder]
      fields: [file_path, speaker_name]
      functions: [VoiceBiometricProcessor, SpeechQualityAssessment,
                  PitchProcessor, LMProcessor, SSLProcessor]
      mode: file_path
      # skip_samples_without_dump: true
    # debug: ~

sampler:
  train:
    type: WeightedSampler
    comb_by_len: true
    fields_to_compute_weight: [lang, speaker_name, intonation_type, uid]
    # fields_to_compute_weight: [speaker_name, intonation_type]  # for finetune
    epoch_size: 100000
    chunks_ratio: [0.3, 0.3, 0.2, 0.2]
  test:
    type: SimpleSampler
    comb_by_len: true
