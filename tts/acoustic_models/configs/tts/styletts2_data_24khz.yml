### Data configuration ###

dirs:
  data_root: &data_root ../../../examples/simple_datasets/speech/SEGS
  dump_folder: &dump_folder dump_24KHz_styletts2

file_search:
  ext: .TextGridStage3
  with_subfolders: true

data_server:
  n_processes: { default: 32, debug: 1 }
  # n_gpus: { default: 1, debug: 0 }

dataset:
  subsets: [train, test]
  split_type: auto  # auto, manual
  split_ratio: { default: 0.999, debug: 0.5 }
  max_num_samples: { default: 0, debug: 40 }
  directory_filter:
    include: { default: ~, ru: RU, en: EN }
    exclude: ["!"]

parser:
  type: TTSDSParser
  dump:
    default: !join [*data_root, *dump_folder]  # fast dataset load
    # debug: ~
  pipe: [audio_strip, split_by_phrases, check_phoneme_length, get_simple_intonation_type]
  pipe_cfg:
    audio_strip:
      pad: 0.25
      add_fade: true
    split_by_phrases:
      max_duration: 10  # 10, 12, 15
    check_phoneme_length:
      max_len: 0.4
    get_simple_intonation_type:
      punctuation_marks: [".", "?"]

preproc:
  pipe: [load_audio, load_audio_segmentation,
         voice_bio, speech_quality, spectrogram, melscale, add_gate_value,
         add_pauses_from_timestamps, add_service_tokens, text, lm,
         calc_durations, average_by_time]
  pipe_cfg:
    load_audio:
      type: SignalProcessor
      pipe: [load]
      pipe_cfg:
        load:
          sample_rate: 24000
    voice_bio:
      type: VoiceBiometricProcessor
      model_type: wespeaker
      max_audio_duration: 5
      random_crop: true
    speech_quality:
      type: SpeechQualityAssessment
      max_audio_duration: 5
      random_crop: true
    spectrogram:
      type: SpectralProcessor
      pipe: [magnitude, energy]
      pipe_cfg:
        magnitude:
          n_fft: 1024
          hop_len: 320
          win_len: 1024
    melscale:
      type: MelProcessor
      pipe: [linear_to_mel, amp_to_db, normalize]
      pipe_cfg:
        linear_to_mel:
          n_mels: 80
          f_min: 0
          f_max: 8000
    pitch:
      type: PitchProcessor
      method: torchcrepe
    add_pauses_from_timestamps:
      step: 0.05
      calc_noise_level: true
    text:
      type: TTSTextProcessor
      lang: MULTILANG
      # lang: { default: MULTILANG, ru: RU, en: EN, ml: MULTILANG }
    lm:
      type: LMProcessor
      lang: { default: MULTILANG, ru: RU, en: EN }
      model_name:
        default: google-bert/bert-base-multilingual-cased
        ru: ai-forever/sbert_large_nlu_ru
      by_transcription: False
    timedim_interpolation:
      features: [ssl_feat]
      shape_as: mel
    average_by_time:
      attributes: [durations, rate, energy]
      use_quantile: true

singleton_handlers:
  handlers: [SpeakerIDSetter]
  SpeakerIDSetter: {}
    # langs_filter: RU
    # min_duration: { default: 1.0, debug: ~ }
    # resume_from_checkpoint: /path/to/checkpoint

collate:
  type: TTSCollate
  # multiple:
  #  spec: 16

processor:
  type: DataProcessor
  output_collated_only: true
  dump:
    default:
      data_root: *data_root
      folder_path: !join [*data_root, *dump_folder]
      fields: [file_path, speaker_name]
      functions: [VoiceBiometricProcessor, XPBertProcessor, LMProcessor]
      mode: file_path
      # skip_samples_without_dump: true
    debug:
      data_root: *data_root
      folder_path: !join [*data_root, *dump_folder]
      mode: file_path
      full_dump: true
      # skip_samples_without_dump: true

sampler:
  train:
    type: WeightedSampler
    comb_by_len: true
    epoch_size: 100000
    fields_to_compute_weight: [lang, speaker_name, intonation_type, uid]
    # fields_to_compute_weight: [speaker_name, intonation_type]  # for finetune
    chunks_ratio: [0.3, 0.3, 0.2, 0.2]
  test:
    type: SimpleSampler
    comb_by_len: true
