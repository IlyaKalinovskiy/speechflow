# pytorch_lightning==1.8.6
seed_everything: 1234

data:
  class_path: tts.vocoders.vocos.vocos.dataset.VocosDataModule
  init_args:
    train_params:
      data_cfg_path: configs/data_24khz.yml
      debug: true
      batch_size: 8

    val_params:
      data_cfg_path: configs/data_24khz.yml
      debug: true
      batch_size: 8

model:
  class_path: tts.vocoders.vocos.vocos.experiment.VocosExp
  init_args:
    sample_rate: 24000
    initial_learning_rate: 5e-4
    mel_loss_coeff: 5.0
    mrd_loss_coeff: 0.1
    num_warmup_steps: 0 # Optimizers warmup steps
    pretrain_mel_steps: 0  # 0 means GAN objective from the first iteration
    with_cdpam: false
    cdpam_every: 1
    cdpam_device: cuda:0

    # automatic evaluation
    evaluate_utmos: false
    evaluate_pesq: false
    evaluate_periodicty: false

    feature_extractor:
      class_path: tts.vocoders.vocos.vocos.feature_extractors.AudioFeatures
      init_args:
        input_feat_type: mel_spec

    backbone:
      class_path: tts.vocoders.vocos.vocos.models.VocosResNetBackbone
      init_args:
        input_channels: 256
        dim: 1024
        num_blocks: 4
        # intermediate_dim: 1536
        # num_layers: 12

    head:
      class_path: tts.vocoders.vocos.vocos.heads.DACHead
      init_args:
        dim: 1024
        # with_dac_loss: true
        # dac_loss_every_iter: 1
        # dac_loss_max_iter: 10000
        with_sm_loss: true
        sm_loss_every_iter: 3

trainer:
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: vc_vocos_logs_RU_FV2_mel_l4_gain
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        filename: vocos_checkpoint_{epoch}_{step}_{val_loss:.4f}
        save_top_k: 3
        save_last: true
    - class_path: tts.vocoders.vocos.vocos.helpers.GradNormCallback

  # Lightning calculates max_steps across all optimizer steps (rather than number of batches)
  # This equals to 2M steps per generator and 2M per discriminator
  max_steps: 8000000
  # accumulate_grad_batches: 3
  # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  limit_val_batches: 100
  accelerator: cpu
  # strategy: ddp
  devices: 1
  log_every_n_steps: 100
  # precision: bf16
  # resume_from_checkpoint:
