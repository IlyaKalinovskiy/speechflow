### Data Configuration ###

dirs:
  data_root: &data_root ../../../examples/simple_datasets/speech/SEGS
  dump_folder: &dump_folder dump_24KHz

file_search:
  ext: .TextGridStage3
  with_subfolders: True

data_server:
  n_processes: { default: 6, debug: 1 }
  # n_gpus: [2]

dataset:
  subsets: [train, test]
  split_type: auto  # auto, manual
  split_ratio: { default: 0.999, debug: 0.5 }
  max_num_samples: { default: 0, debug: 40 }
  directory_filter:
    exclude: ["!"]

parser:
  type: TTSDSParser
  dump: !join [*data_root, *dump_folder]
  pipe: [wave_strip, split_by_phrases, check_phoneme_length]
  pipe_cfg:
    wave_strip:
      pad: 0.25
      add_fade: True
    split_by_phrases:
      max_duration: 10  # 10, 12, 15
    check_phoneme_length:
      max_len: 0.4

preproc:
  pipe: [wave,
         style, backup_field, voice_bio, speech_quality,
         augment_wave_1, augment_wave_2,
         spectrogram, melscale, ssl_features,
         energy, pitch, enhancement_energy, enhancement_pitch,
         norm, average_by_time,
         add_pauses_from_timestamps, text,
         int_durations, calc_invert_durations, phonemes_by_frames, float_durations,
         trim, mu_law]
  pipe_cfg:
    wave:
      type: SignalProcessor
      pipe: [load]
      pipe_cfg:
        load:
          sample_rate: 24000
    augment_wave_1:
      type: WaveAugProcessor
      pipe: [pitch_shift]
      pipe_cfg:
        pitch_shift:
          p: 0.25
          min_semitones: -12
          max_semitones: 12
    augment_wave_2:
      type: WaveAugProcessor
      pipe: [gain]
      pipe_cfg:
        gain:
          p: 0.25
        gain_curve:
          p: 0.25
          min_ratio: 0.5
          max_ratio: 1.5
    augment_wave_3:
      type: WaveAugProcessor
      pipe: [vtlp]
      pipe_cfg:
        vtlp:
          p: 0.25
          alpha_min: 0.95
          alpha_max: 1.05
    style:
      type: VoiceBiometricProcessor
      model_type: speechbrain
      max_wave_duration: 5
      random_crop: True
    backup_field:
      key: speaker_emb
      as_key: style_embedding
    voice_bio:
      type: VoiceBiometricProcessor
      model_type: wespeaker
      max_wave_duration: 5
      random_crop: True
    speech_quality:
      type: SpeechQualityAssessment
    spectrogram:
      type: SpectralProcessor
      pipe: [magnitude]
      pipe_cfg:
        magnitude:
          n_fft: 1024
          hop_len: 320
          win_len: 1024
    melscale:
      type: MelProcessor
      pipe: [linear_to_mel, amp_to_db, normalize]
      pipe_cfg:
        linear_to_mel:
          n_mels: 80
          f_min: 0
          f_max: 8000
    ssl_features:
      type: SSLProcessor
      ssl_type: Wav2Vec
      ssl_params:
        feature_type: encode_level
        level: 4
      resize_from: magnitude
    energy:
      type: SpectralProcessor
      pipe: [energy]
    pitch:
      type: PitchProcessor
      method: pyworld
    enhancement_energy:
      type: signal_enhancement
      attributes: energy
      smooth: True
    enhancement_pitch:
      type: signal_enhancement
      attributes: pitch
      smooth: True
    average_by_time:
      attributes: [energy, pitch]
      use_quantile: True
    norm:
      type: normalize
      attributes: [energy, pitch]
      normalize_by: sample
    energy_norm:
      type: normalize
      attributes: [energy]
      normalize_by: constant
      min_value: 0
      max_value: 200
    pitch_norm:
      type: normalize
      attributes: [pitch]
      normalize_by: constant
      min_value: 0
      max_value: 880
    add_pauses_from_timestamps:
      step: 0.05
    text:
      type: TextProcessor
      lang: MULTILANG
    int_durations:
      type: calc_durations
      as_int: True
    calc_invert_durations:
      token_level: True
    float_durations:
      type: calc_durations
      as_int: False
    trim:
      type: SignalProcessor
      pipe: [trim]
      pipe_cfg:
        trim:
          random_chunk: True
          num_samples_per_chunk: 40952
    mu_law:
      type: SignalProcessor
      pipe: [mu_law_encode]
      pipe_cfg:
        mu_law_encode:
          bits: 16

singleton_handlers:
  handlers: [SpeakerIDSetter]
  SpeakerIDSetter:
    langs_filter: RU
    min_duration: { default: 2.0, debug: ~ }
  StatisticsRange:
    statistics_file: !join [*data_root, *dump_folder, ranges.json]
  DatasetStatistics:
    dump: !join [*data_root, *dump_folder]

collate:
  type: TTSCollate

processor:
  type: DataProcessor
  output_collated_only: True
  verbose_logging: False
  dump:
    default:
      data_root: *data_root
      folder_path: !join [*data_root, *dump_folder]
      fields: [file_path, speaker_name]
      functions: [VoiceBiometricProcessor, SpeechQualityAssessment]
      mode: file_path
      # skip_samples_without_dump: True
    debug: ~

sampler:
  train:
    type: WeightedSampler
    fields_to_compute_weight: [speaker_name, uid]
    epoch_size: 20000
    chunks_ratio: [0.6, 0.4]
  test:
    type: SimpleSampler
